{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T06:26:14.519027Z",
     "start_time": "2020-03-20T06:26:14.510574Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T06:27:50.886153Z",
     "start_time": "2020-03-20T06:27:25.903632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint version 1 is up-to-date.\n",
      "charset: ['', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '}']\n",
      "Using CUDNN LSTM backend on GPU\n",
      "Successfully load the model's weights\n",
      "INFO:tensorflow:Restoring parameters from /home/chenlu/calamari/models/antiqua_modern/4.ckpt\n",
      "Using CUDNN LSTM backend on GPU\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle, glob, time, sys, io\n",
    "from cleverhans import utils_tf\n",
    "from util import cvt2Image, sparse_tuple_from\n",
    "from calamari_ocr.ocr.backends.tensorflow_backend.tensorflow_model import TensorflowModel\n",
    "from calamari_ocr.ocr import Predictor\n",
    "checkpoint = '/home/chenlu/calamari/models/antiqua_modern/4.ckpt.json'\n",
    "predictor = Predictor(checkpoint=checkpoint, batch_size=1, processes=10)\n",
    "\n",
    "network = predictor.network\n",
    "sess, graph = network.session, network.graph\n",
    "codec = network.codec\n",
    "charset = codec.charset\n",
    "encode, decode = codec.encode, codec.decode\n",
    "code2char, char2code = codec.code2char, codec.char2code\n",
    "\n",
    "def invert(data): # 反色\n",
    "    if data.max() < 1.5:\n",
    "        return 1 - data\n",
    "    else:\n",
    "        return 255 - data\n",
    "\n",
    "def transpose(data): # 旋转90度\n",
    "    if len(data.shape) != 2:\n",
    "        return np.swapaxes(data, 1, 2)\n",
    "    else:\n",
    "        return data.T\n",
    "\n",
    "def cvt2raw(data):\n",
    "    return transpose(invert(data))\n",
    "\n",
    "def show(img):\n",
    "    return cvt2Image(cvt2raw(img))\n",
    "\n",
    "def preprocess(img_list):\n",
    "    # preprocess the image before feeding it into the model\n",
    "    images = [np.array(img_list[i].convert('L'), dtype='uint8') for i in range(len(img_list))]\n",
    "    images, params = zip(*predictor.data_preproc.apply(images))\n",
    "    images, len_x = network.zero_padding(images)  # padding images to same fixed-length images\n",
    "    images = images / 255 # normalized images\n",
    "    input_img = images.reshape(images.shape[:3])\n",
    "    return input_img, len_x\n",
    "\n",
    "eps, eps_iter, nb_iter = 0.2, 5.0, 1000\n",
    "batch_size = 100\n",
    "clip_min, clip_max = 0.0, 1.0\n",
    "# build graph\n",
    "with graph.as_default():\n",
    "    # _ 是data_iterator如果是dataset input的话\n",
    "    inputs, input_seq_len, targets, dropout_rate, _, _ = network.create_placeholders()\n",
    "    output_seq_len, time_major_logits, time_major_softmax, logits, softmax, decoded, sparse_decoded, scale_factor, log_prob = \\\n",
    "                        network.create_network(inputs, input_seq_len, dropout_rate, reuse_variables=tf.AUTO_REUSE)\n",
    "    loss = tf.nn.ctc_loss(labels=targets,\n",
    "                          inputs=time_major_logits,\n",
    "                          sequence_length=output_seq_len,\n",
    "                          time_major=True,\n",
    "                          ctc_merge_repeated=True,\n",
    "                          ignore_longer_outputs_than_inputs=True)\n",
    "    loss = -tf.reduce_mean(loss, name='loss')\n",
    "    grad, = tf.gradients(loss, inputs)\n",
    "\n",
    "    # Normalize current gradient and add it to the accumulated gradient\n",
    "    red_ind = list(range(1, len(grad.get_shape())))\n",
    "    avoid_zero_div = tf.cast(1e-12, grad.dtype)\n",
    "    divisor = tf.reduce_mean(tf.abs(grad), red_ind, keepdims=True)\n",
    "    norm_grad = grad / tf.maximum(avoid_zero_div, divisor)\n",
    "\n",
    "    m = tf.placeholder(tf.float32,\n",
    "                       shape=inputs.get_shape().as_list(),\n",
    "                       name=\"momentum\")\n",
    "    acc_m = m + norm_grad\n",
    "\n",
    "    grad = acc_m\n",
    "    # ord=np.inf\n",
    "    optimal_perturbation = tf.sign(grad)\n",
    "    optimal_perturbation = tf.stop_gradient(optimal_perturbation)\n",
    "    scaled_perturbation_inf = utils_tf.mul(0.01, optimal_perturbation)\n",
    "    # ord=2\n",
    "    square = tf.maximum(1e-12, tf.reduce_sum(tf.square(grad), axis=red_ind, keepdims=True))\n",
    "    optimal_perturbation = grad / tf.sqrt(square)\n",
    "    scaled_perturbation_2 = utils_tf.mul(0.01, optimal_perturbation)\n",
    "\n",
    "def attack(input_img, len_x, target_txt, pert_type='2'):\n",
    "    target_index_list = [np.asarray([c for c in encode(t)]) for t in target_txt]\n",
    "    with graph.as_default():\n",
    "        adv_img = input_img.copy()\n",
    "        m0 = np.zeros(input_img.shape)\n",
    "        record_iter = np.zeros(input_img.shape[0])  # 0代表没成功\n",
    "\n",
    "        start = time.time()\n",
    "        for i in tqdm(range(nb_iter)):\n",
    "            # perform attack\n",
    "            batch_iter = len(input_img) // batch_size\n",
    "            batch_iter = batch_iter if len(input_img) % batch_size == 0 else batch_iter + 1\n",
    "            for batch_i in range(batch_iter):\n",
    "                batch_input_img = input_img[batch_size * batch_i:batch_size * (batch_i + 1)]\n",
    "                batch_adv_img = adv_img[batch_size * batch_i:batch_size * (batch_i + 1)]\n",
    "                batch_len_x = len_x[batch_size * batch_i:batch_size * (batch_i + 1)]\n",
    "                batch_m0 = m0[batch_size * batch_i:batch_size * (batch_i + 1)]\n",
    "                batch_target_txt = target_txt[batch_size * batch_i:batch_size * (batch_i + 1)]\n",
    "                batch_tmp_y = [np.asarray([c - 1 for c in encode(t)]) for t in batch_target_txt]\n",
    "                batch_y = sparse_tuple_from(batch_tmp_y)\n",
    "                batch_record_iter = record_iter[batch_size * batch_i:batch_size * (batch_i + 1)]\n",
    "\n",
    "                scaled_perturbation = scaled_perturbation_2 if pert_type == '2' else scaled_perturbation_inf\n",
    "                batch_pert = sess.run(scaled_perturbation, # pert type\n",
    "                                      feed_dict={\n",
    "                                          inputs: batch_adv_img,\n",
    "                                          input_seq_len: batch_len_x,\n",
    "                                          m: batch_m0,\n",
    "                                          targets: batch_y,\n",
    "                                          dropout_rate: 0,\n",
    "                                      })\n",
    "                batch_pert[batch_pert > 0] = 0 ###########################3\n",
    "                batch_pert[batch_record_iter != 0] = 0\n",
    "                batch_adv_img = batch_adv_img + eps_iter * batch_pert\n",
    "                batch_adv_img = batch_input_img + np.clip(batch_adv_img - batch_input_img, -eps, eps)\n",
    "                batch_adv_img = np.clip(batch_adv_img, clip_min, clip_max)\n",
    "                adv_img[batch_size * batch_i:batch_size * (batch_i + 1)] = batch_adv_img\n",
    "\n",
    "            record_adv_text = []\n",
    "            # check whether attack success\n",
    "            for batch_i in range(batch_iter):\n",
    "                batch_adv_img = adv_img[batch_size * batch_i:batch_size * (batch_i + 1)]\n",
    "                batch_len_x = len_x[batch_size * batch_i:batch_size * (batch_i + 1)]\n",
    "                batch_target_index = target_index_list[batch_size * batch_i:batch_size * (batch_i + 1)]\n",
    "                batch_adv_text = sess.run(decoded,\n",
    "                                          feed_dict={\n",
    "                                              inputs: batch_adv_img,\n",
    "                                              input_seq_len: batch_len_x,\n",
    "                                              dropout_rate: 0,\n",
    "                                          })\n",
    "                batch_adv_index = TensorflowModel._TensorflowModel__sparse_to_lists(batch_adv_text)\n",
    "                record_adv_text += [''.join(decode(index)) for index in batch_adv_index]\n",
    "                for j in range(len(batch_target_index)):\n",
    "                    # attack img idx_j successfully at iter i\n",
    "                    idx_j = batch_size * batch_i + j\n",
    "                    adv_index, target_index = batch_adv_index[j], batch_target_index[j]\n",
    "                    if np.sum(adv_index != target_index) == 0 and record_iter[idx_j] == 0:\n",
    "                        record_iter[idx_j] = i\n",
    "            # check whether all examples are successful\n",
    "            if np.sum(record_iter == 0) == 0:\n",
    "                break\n",
    "\n",
    "        duration = time.time() - start\n",
    "        print(f\"{i} break. Time cost {duration:.4f} s\")\n",
    "    return adv_img, record_adv_text, record_iter, (duration, i)\n",
    "\n",
    "# paragraph\n",
    "data_path = '/home/chenlu/research/TextRecognitionDataGenerator/paragraph_image_data/'\n",
    "font = 'Courier'\n",
    "with open(f'{data_path}/{font}.pkl', 'rb') as f:\n",
    "    img_list, line_img_list, gt_txt = pickle.load(f)\n",
    "\n",
    "width, height = line_img_list[0][0].size\n",
    "\n",
    "line_img = []\n",
    "for line_list in line_img_list:\n",
    "    line_img += line_list\n",
    "\n",
    "line_text = []\n",
    "for g_txt in gt_txt:\n",
    "    line_text += g_txt\n",
    "\n",
    "len_x = [img.size[0] for img in line_img]\n",
    "nb_line = len(line_img)\n",
    "width = max(len_x)\n",
    "input_img = (np.ones((nb_line, height, width)) * 255).astype('uint8')\n",
    "for row, ih in enumerate(range(nb_line)):\n",
    "    input_img[row, :, :line_img[row].size[0]] = np.array(line_img[row])\n",
    "input_img = np.swapaxes(1 - (input_img / 255), 1, 2)\n",
    "input_img, len_x = preprocess(line_img)\n",
    "\n",
    "line_img_num = [len(line) for line in gt_txt]\n",
    "\n",
    "record = [0]\n",
    "for nb in line_img_num:\n",
    "    record.append(record[-1] + nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cand_input_img = []\n",
    "cand_len_x = []\n",
    "cand_gt_txt = []\n",
    "for i in range(len(line_img_num)):\n",
    "    print(i)\n",
    "    s, e = record[i], record[i+1]\n",
    "    adv_img, record_adv_text, record_iter, (duration, i) = attack(input_img[s:e], len_x[s:e], line_text[s:e])\n",
    "    if np.sum(record_iter == 0) == 0:\n",
    "        cand_input_img.append(adv_img)\n",
    "        cand_len_x.append(len_x[s:e])\n",
    "        cand_gt_txt.append(line_text[s:e])\n",
    "input_img, len_x, gt_txt = cand_input_img, cand_len_x, cand_gt_txt\n",
    "\n",
    "# load English dictionary en_list\n",
    "from trdg.utils import load_dict\n",
    "en_list = load_dict('en_alpha') # 只包括字母的单词\n",
    "\n",
    "# 将English dictionary中的word按照长度分类 en_dict\n",
    "from collections import defaultdict\n",
    "en_dict = defaultdict(list)\n",
    "for w in en_list:\n",
    "    en_dict[len(w)].append(w.lower())\n",
    "\n",
    "import random\n",
    "def find_new_word(w):\n",
    "    new_w = random.choice(en_dict[len(w)])\n",
    "    if w.istitle():\n",
    "        new_w = new_w[0].upper() + new_w[1:]\n",
    "    return new_w\n",
    "\n",
    "target_txt = []\n",
    "for gt_p in gt_txt:\n",
    "    target_i = []\n",
    "    for gt in gt_p:\n",
    "        sent = gt.split(' ')\n",
    "        target_t = gt\n",
    "        for k, w in enumerate(sent):\n",
    "            if 4 <= len(w) <= 6 and re.match(r'^[a-z]*$', w.lower()):\n",
    "                target_t = ' '.join(sent[:k] + [find_new_word(w)] + sent[k + 1:])\n",
    "                break\n",
    "        target_i.append(target_t)\n",
    "    target_txt.append(target_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T07:03:54.063645Z",
     "start_time": "2020-03-20T07:03:54.057162Z"
    }
   },
   "outputs": [],
   "source": [
    "def extend(input_):\n",
    "    tmp_list = []\n",
    "    for i in input_:\n",
    "        tmp_list += list(i)\n",
    "    return tmp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T06:57:00.304188Z",
     "start_time": "2020-03-20T06:57:00.294082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1577, 48)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img_list = []\n",
    "for imgs in input_img:\n",
    "    for i in imgs:\n",
    "        input_img_list.append(i)\n",
    "input_img = np.asarray(input_img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T06:31:58.969602Z",
     "start_time": "2020-03-20T06:31:58.937320Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extend' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c5133cf5f013>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlen_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgt_txt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_txt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtarget_txt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_txt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'extend' is not defined"
     ]
    }
   ],
   "source": [
    "input_img = np.asarray(extend(input_img))\n",
    "len_x = extend(len_x)\n",
    "gt_txt = extend(gt_txt)\n",
    "target_txt = extend(target_txt)\n",
    "\n",
    "with open(f'{data_path}/{font}-new.pkl', 'wb') as f:\n",
    "    pickle.dump((None, input_img, len_x, gt_txt, target_txt), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T07:04:53.481836Z",
     "start_time": "2020-03-20T07:04:53.437327Z"
    }
   },
   "outputs": [],
   "source": [
    "input_img_list = []\n",
    "for imgs in cand_input_img:\n",
    "    for i in imgs:\n",
    "        input_img_list.append(i)\n",
    "input_img = np.asarray(input_img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T07:12:33.500433Z",
     "start_time": "2020-03-20T07:12:33.495409Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T07:19:43.000783Z",
     "start_time": "2020-03-20T07:19:42.569716Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '/home/chenlu/research/TextRecognitionDataGenerator/paragraph_image_data/'\n",
    "with open(f'{data_path}/Helvetica-new.pkl', 'rb') as f:\n",
    "    _, input_img, len_x, gt_txt, target_txt = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T07:19:43.013506Z",
     "start_time": "2020-03-20T07:19:43.005091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(631, 631, 631, 631)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_img), len(len_x), len(gt_txt), len(target_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ocr1]",
   "language": "python",
   "name": "conda-env-ocr1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
