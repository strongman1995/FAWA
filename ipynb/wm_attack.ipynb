{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T12:22:16.506949Z",
     "start_time": "2020-02-22T12:22:16.500913Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T12:22:16.947165Z",
     "start_time": "2020-02-22T12:22:16.939894Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time, io\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "from cleverhans import utils_tf\n",
    "from util import cvt2Image, sparse_tuple_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T12:22:32.697949Z",
     "start_time": "2020-02-22T12:22:17.354555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint version 1 is up-to-date.\n",
      "charset: ['', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '}']\n",
      "Using CUDNN LSTM backend on GPU\n",
      "Successfully load the model's weights\n",
      "INFO:tensorflow:Restoring parameters from /home/chenlu/calamari/models/antiqua_modern/4.ckpt\n"
     ]
    }
   ],
   "source": [
    "from calamari_ocr.ocr.backends.tensorflow_backend.tensorflow_model import TensorflowModel\n",
    "from calamari_ocr.ocr import Predictor\n",
    "checkpoint = '/home/chenlu/calamari/models/antiqua_modern/4.ckpt.json'\n",
    "predictor = Predictor(checkpoint=checkpoint, batch_size=1, processes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T12:22:32.710111Z",
     "start_time": "2020-02-22T12:22:32.702067Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = predictor.network\n",
    "sess, graph = network.session, network.graph\n",
    "codec = network.codec\n",
    "charset = codec.charset\n",
    "encode, decode = codec.encode, codec.decode\n",
    "code2char, char2code = codec.code2char, codec.char2code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T12:22:32.751834Z",
     "start_time": "2020-02-22T12:22:32.714084Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def invert(data): # 反色\n",
    "    if data.max() < 1.5:\n",
    "        return 1 - data\n",
    "    else:\n",
    "        return 255 - data\n",
    "\n",
    "def transpose(data): # 旋转90度\n",
    "    if len(data.shape) != 2:\n",
    "        return np.swapaxes(data, 1, 2)\n",
    "    else:\n",
    "        return data.T\n",
    "\n",
    "def cvt2raw(data):\n",
    "    return transpose(invert(data))\n",
    "\n",
    "def show(img):\n",
    "    return cvt2Image(cvt2raw(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T13:03:22.627446Z",
     "start_time": "2020-02-22T13:03:22.126298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDNN LSTM backend on GPU\n"
     ]
    }
   ],
   "source": [
    "# build graph\n",
    "with graph.as_default():\n",
    "    # _ 是data_iterator如果是dataset input的话\n",
    "    inputs, input_seq_len, targets, dropout_rate, _, _ = network.create_placeholders(\n",
    "    )\n",
    "    output_seq_len, time_major_logits, time_major_softmax, logits, softmax, decoded, sparse_decoded, scale_factor, log_prob = \\\n",
    "                        network.create_network(inputs, input_seq_len, dropout_rate, reuse_variables=tf.AUTO_REUSE)\n",
    "    loss = tf.nn.ctc_loss(labels=targets,\n",
    "                          inputs=time_major_logits,\n",
    "                          sequence_length=output_seq_len,\n",
    "                          time_major=True,\n",
    "                          ctc_merge_repeated=True,\n",
    "                          ignore_longer_outputs_than_inputs=True)\n",
    "    loss = -tf.reduce_mean(loss, name='loss')\n",
    "    grad, = tf.gradients(loss, inputs)\n",
    "\n",
    "    # Normalize current gradient and add it to the accumulated gradient\n",
    "    red_ind = list(range(1, len(grad.get_shape())))\n",
    "    avoid_zero_div = tf.cast(1e-12, grad.dtype)\n",
    "    divisor = tf.reduce_mean(tf.abs(grad), red_ind, keepdims=True)\n",
    "    norm_grad = grad / tf.maximum(avoid_zero_div, divisor)\n",
    "\n",
    "    m = tf.placeholder(tf.float32,\n",
    "                       shape=inputs.get_shape().as_list(),\n",
    "                       name=\"momentum\")\n",
    "    acc_m = m + norm_grad\n",
    "    \n",
    "    # watermark mask\n",
    "    mask = tf.placeholder(tf.float32,\n",
    "                       shape=inputs.get_shape().as_list(),\n",
    "                       name=\"mask\")\n",
    "    grad = tf.multiply(acc_m, mask, name=\"mask_op\")\n",
    "    # eps_iter = 0.01\n",
    "    # ord=np.inf\n",
    "    optimal_perturbation = tf.sign(grad)\n",
    "    optimal_perturbation = tf.stop_gradient(optimal_perturbation)\n",
    "    scaled_perturbation_inf = utils_tf.mul(0.01, optimal_perturbation)\n",
    "    # ord=1\n",
    "    abs_grad = tf.abs(grad)\n",
    "    max_abs_grad = tf.reduce_max(abs_grad, axis=red_ind, keepdims=True)\n",
    "    tied_for_max = tf.to_float(tf.equal(abs_grad, max_abs_grad))\n",
    "    num_ties = tf.reduce_sum(tied_for_max, axis=red_ind, keepdims=True)\n",
    "    optimal_perturbation = tf.sign(grad) * tied_for_max / num_ties\n",
    "    scaled_perturbation_1 = utils_tf.mul(0.01, optimal_perturbation)\n",
    "    # ord=2\n",
    "    square = tf.maximum(\n",
    "        1e-12, tf.reduce_sum(tf.square(grad), axis=red_ind, keepdims=True))\n",
    "    optimal_perturbation = grad / tf.sqrt(square)\n",
    "    scaled_perturbation_2 = utils_tf.mul(0.01, optimal_perturbation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T12:22:49.985945Z",
     "start_time": "2020-02-22T12:22:48.665777Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clip_min, clip_max = 0.0, 1.0\n",
    "eps = 0.2\n",
    "nb_iter = 1000\n",
    "batch_size = 100\n",
    "pert_type = '2'\n",
    "eps_iter = 5.0\n",
    "case = 'easy'\n",
    "font_name = 'Arial' # 'Courier' 'Georgia' 'Helvetica' 'times' 'Arial'\n",
    "\n",
    "img_data_path = '/home/chenlu/research/TextRecognitionDataGenerator/word_image_data'\n",
    "with open(f'{img_data_path}/{font_name}-{case}.pkl', 'rb') as f:\n",
    "    img_list, input_img, len_x, gt_txt, target_txt = pickle.load(f)\n",
    "input_img = np.asarray(input_img)\n",
    "nb_sample = 50\n",
    "input_img, len_x, gt_txt, target_txt = input_img[:nb_sample], len_x[:nb_sample], gt_txt[:nb_sample], target_txt[:nb_sample]\n",
    "\n",
    "title = f\"{font_name}-{case}-l{pert_type}-eps{eps}-ieps{eps_iter}-iter{nb_iter}\"\n",
    "with open(f'attack_result/{title}.pkl', 'rb') as f:\n",
    "    adv_img, record_adv_text, record_iter, (duration, total_iter) = pickle.load(f)\n",
    "adv_img, record_adv_text, record_iter = adv_img[:nb_sample], record_adv_text[:nb_sample], record_iter[:nb_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T12:23:29.461949Z",
     "start_time": "2020-02-22T12:23:29.438185Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import morphology\n",
    "import cv2\n",
    "def find_wm_pos(adv_img, input_img, ret_frame_img=False):\n",
    "    pert = np.abs(cvt2raw(adv_img) - cvt2raw(input_img))\n",
    "    pert = (pert > 1 * 1e-2) * 255.0\n",
    "    wm_pos_list = []\n",
    "    frame_img_list = []\n",
    "    for src in pert:\n",
    "        kernel = np.ones((3, 3), np.uint8)  # 设置卷积核3*3\n",
    "        dilate = cv2.dilate(src, kernel, iterations=2)  # 图像的膨胀\n",
    "        erode = cv2.erode(dilate, kernel, iterations=2)  # 图像的腐蚀\n",
    "        remove = morphology.remove_small_objects(erode.astype('bool'), min_size=0)\n",
    "        contours, _ = cv2.findContours((remove * 255).astype('uint8'), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        wm_pos, frame_img = [], []\n",
    "        for cont in contours:\n",
    "            left_point = cont.min(axis=1).min(axis=0)\n",
    "            right_point = cont.max(axis=1).max(axis=0)\n",
    "            wm_pos.append(np.hstack((left_point, right_point)))\n",
    "            if ret_frame_img:\n",
    "                img = cv2.rectangle(\n",
    "                    (remove * 255).astype('uint8'), (left_point[0], left_point[1]),\n",
    "                    (right_point[0], right_point[1]), (255, 255, 255), 2)\n",
    "                frame_img.append(img)\n",
    "        wm_pos_list.append(wm_pos)\n",
    "        frame_img_list.append(frame_img)\n",
    "    \n",
    "    if ret_frame_img:\n",
    "        return (wm_pos_list, frame_img_list)\n",
    "    else:\n",
    "        return wm_pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T12:23:35.525729Z",
     "start_time": "2020-02-22T12:23:35.374772Z"
    }
   },
   "outputs": [],
   "source": [
    "pos, frames = find_wm_pos(adv_img, input_img, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T12:23:38.429244Z",
     "start_time": "2020-02-22T12:23:38.417918Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 按面积大小把pos从大到小排个序\n",
    "new_pos = []\n",
    "for _pos in pos:\n",
    "    if len(_pos) > 1:\n",
    "        new_pos.append(sorted(_pos, key=lambda x: (x[3]-x[1])*(x[2]-x[0]), reverse=True))\n",
    "    else:\n",
    "        new_pos.append(_pos)\n",
    "pos = new_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T12:26:00.838379Z",
     "start_time": "2020-02-22T12:26:00.828998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMEAAAAwCAAAAACN50H8AAAA+0lEQVR4nO2Z2w7CQAhEZ43//8v4orEmwwo1hkE5T00vCVMGlm0XNhiwdtcluFQH8GWsOoABgMmnoX8d9FdwJeceTVTeQAAiOVDX0d9FdM21wD0yRBR4t2nQ30VBBcLlzO3BA9a0UsZFmhPG39SBMJk62D5SRj4HYgI28XTpR2w2ZfjDqhWLSrqIRFudlf69aBTU4yqQnCAYXh2+E1Bdv0+i3fSATvAAfmFN7l/Jzht1y0AtA24O9AJ18VzUR8Lnc1E1gW5Kx1KTEXNiPRBbr8/sD6QE5HKwXg6qtzZ3uILDW/bD1BDg/QEBNhvLpWUjgua3uQztBQzD0I4biFMhUwnSo+MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=193x48 at 0x7F98702337B8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvt2Image(frames[0][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T12:26:02.159494Z",
     "start_time": "2020-02-22T12:26:02.145750Z"
    }
   },
   "outputs": [],
   "source": [
    "from trdg.generators import GeneratorFromStrings\n",
    "\n",
    "def gen_wm(RGB):\n",
    "    generator = GeneratorFromStrings(\n",
    "        strings=['eccv'],\n",
    "        count=1,  # 五种字体\n",
    "        fonts=['Impact.ttf'],  # default: []\n",
    "        language='en',\n",
    "        size=100,  # 32\n",
    "        skewing_angle=10,\n",
    "        random_skew=False,\n",
    "        blur=0,\n",
    "        random_blur=False,\n",
    "        # gaussian noise (0), plain white (1), quasicrystal (2) or picture (3)\n",
    "        background_type=1,\n",
    "        distorsion_type=0,  # None(0), Sine wave(1),Cosine wave(2),Random(3)\n",
    "        distorsion_orientation=0,\n",
    "        is_handwritten=False,\n",
    "        width=-1,\n",
    "        alignment=1,\n",
    "        text_color=RGB2Hex(RGB),\n",
    "        orientation=0,\n",
    "        space_width=1.0,\n",
    "        character_spacing=0,\n",
    "        margins=(0, 0, 0, 0),\n",
    "        fit=True,\n",
    "    )\n",
    "    img_list = [img for img, _ in generator]\n",
    "    return img_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T12:26:03.402592Z",
     "start_time": "2020-02-22T12:26:03.394185Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RGB格式颜色转换为16进制颜色格式\n",
    "def RGB2Hex(RGB): # RGB is a 3-tuple\n",
    "    color = '#'\n",
    "    for num in RGB:\n",
    "        color += str(hex(num))[-2:].replace('x', '0').upper()\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T13:15:37.578679Z",
     "start_time": "2020-02-22T13:15:37.549215Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 得到水印 mask\n",
    "grayscale = 0 # 灰度值在 76-226 之间有对应的彩色水印值\n",
    "color = (grayscale, grayscale, grayscale)\n",
    "wm_img = gen_wm(color)\n",
    "wm_arr = np.array(wm_img.convert('L'))\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "wm_arr = cv2.dilate(wm_arr, kernel, 2)\n",
    "wm_arr = cv2.erode(wm_arr, kernel, 2)\n",
    "bg_mask = ~(wm_arr != 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T13:15:37.802960Z",
     "start_time": "2020-02-22T13:15:37.787936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAABkCAIAAABM5OhcAAAEYUlEQVR4nO2d23KrMAxF6Znzg3wpn5g+dOqhDgFftOUte6+nzjQlRl7IsiDp1+v12oSw5t/oAYg5+T96AIKR4zhufrvv++MRJJbYtieTGpBYS2PuU0I1loAgsQQELYXhKVzOSipuQyRWMHBVkS1aCgUEiSWqKcmaWgq9uZwV5wLIAYmFpbAkSi/DGXYch6e+EgtCc4ntYNiZfd9BuwHVWMYcx2EyVVF2f5+QWJbY2nDpaJRqTEuhAdDs8nNwE588yyxlLAFBYnVhVVGVvFH6uSfruJVuEktAmLbG6n8GsvMtzDkXW7g2gRWTiFUb5ez1DZ6Rz+twtBRuW7eX4p3wYhk2JEPoEmKQW9ylEBRfw6bRJenIA/3IzhFUroXMWOhZuT9+87tb+Wre3zc8WiKeWP59I072fWe+vRNPrLjwy2pIMLE85wb6XszJxgSD4r18ApqjudS17gP6hnS1WD1zbHXDyw30JpEBil2h4QiCJiG2YdNKXyGWeUwdepL7L9B3GQvn2T2LdfziMBocJNGPHsZyHsRyCMQ6sc4gcR0ExS2d+xp5uHkkJbz5ANJ5Ier3j2INn05OfmbXITieHiNO50KsUUohOiugY1odympsbrqXE6zz3sPwtWwpFhKLBKq8goNLLNq+xsTZzumxmZ6HjSaO/twgJu6PWP3yrqDXCufYD9dSiMDkajEZCRoq4ykapG6UdAId5sb5q6oQPJ4Co1iecY8+wbQwipVhe8NBJr3j1HkXJfh/yD3Wl5eaiXVev/i/WaCfsR9BO78sc4sk+EtkrBDFMoMN5TzG80+7gT/60xD9I0CP4yftY8W6fMU7pGJlKJWGw1KslGZWyDdy/R7jjEX7eALnqEzgbEPEWAoFG4/i5u0Gki7IWG4iYJgJsiaIeeShUxnyXuEluDDpQkKw9FLYUBHKwkKWFqsTquef2FhIrAWTzUDvuWqs1RJAiJuYl1TvCjffjWHQsIIItCXn2hV2ahQo7m20nd19VEcFDSiWyf8RIUxptv2nuKvhPRCxCiM1d/rhYUjS8lsKGTRCN7vbmDJpOYnFMH/MhItPy66Qiimv5ojUzgK7WBkkixcJ5ZNdG7f+ixki1mppZsj3nplH2PaA12JNnBjmkL7hFJzPeqF7hYnOf5AxgZcOrCjWGdsP7/s4F8LsAGJlc2/7DGftnwyf1OEDKCTYrtAKXAUJKuSj+JRAZSxcmjE/GoLVzvedj2JFPBk0VTExCWDch1QXXQp9SE44NycZuBNr4m5WAz3zPYcrVQTYFV7ivEYsaEYnTmKFznyyqgFgjZVk6n8i+eZX0b9oalaiLoUJ3NzLqh4exDIJbsR1UFZ1wt5uKJngtl19zzuKR9jFqqLzdoqUMmQqsX7I/PjkmTSC8vV6vR5f5F8kadajU7Qr1DSLWkrbDWpziyqKlsIzakiKEiiKd/k0H9Wdd0kgSqheChPqRoob2sU6UyuZfJoeG7GEyAj/dIPgRGIJCBJLQPgGT9AnGjhgao0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=200x100 at 0x7F97E8267240>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 灰色水印\n",
    "grayscale = 174 # 灰度值在 76-226 之间有对应的彩色水印值, 为了增加扰动后还在范围内，128-174\n",
    "color = (grayscale, grayscale, grayscale)\n",
    "wm_img = np.array(Image.new(mode=\"RGB\", size=wm_img.size, color=color))\n",
    "wm_img[bg_mask] = 255\n",
    "wm_img = Image.fromarray(wm_img)\n",
    "wm_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T16:33:59.991045Z",
     "start_time": "2020-02-19T16:33:59.974941Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "large_l = []\n",
    "green_val = np.array(list(range(256)))\n",
    "for _gi in range(256):\n",
    "    _r, _g, _b = 255, _gi, 0\n",
    "    large_l.append(_r * 19595 + _g * 38470 + _b * 7471 + 0x8000)\n",
    "normal_l = np.array(large_l, dtype='uint32') >> 16\n",
    "l0_1 = normal_l / 255\n",
    "range_min, range_max = l0_1.min(), l0_1.max()\n",
    "gray_green_map = dict(list(zip(normal_l, green_val)))\n",
    "gray_green_map_array = np.ones((255, ))\n",
    "gray_green_map_array[:76] = gray_green_map[76]\n",
    "gray_green_map_array[227:] = gray_green_map[226]\n",
    "for gray, green in gray_green_map.items():\n",
    "    gray_green_map_array[gray] = green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T16:34:01.931845Z",
     "start_time": "2020-02-19T16:34:01.913192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAABkCAIAAABM5OhcAAAEU0lEQVR4nO2d0bKqMAxF8c79SD/Rv+Q8ONNBREhpdrrT7vWqgzRdpGlAfazrugjhzb/eJyDG5H/vExCUvB5nrz6vVzmJJZZluTKpHok1N94+FVRjCQgSS0DQUpgf43JmqLgdkVjZgFVFvmgpFBAklqjHkDW1FIZzOCuxBVAAEguMsSQqb8MZ9npE6iuxMNwusQMM2/JcQbsB1VjevB4+U5Vk9/cLieWKrw2HjiapxrQUegDNLu+Du/gUWGYpYwkIEqsNr4rK8kGFlqwTVbpJLAFh3Bqr+RnI1o9wZ1tswdoEXowiVm2Ud++/4Rn3vHZHS+GyLM1eii/yi+XYkEyhS4qTTLwUguLr2DQ6pBy5ox+7MWLKtZwZCz0r58e//elevrr39wEkFCu+b8TJc2W+vZNQrLzwy+pHNrEi5wb6WcTJxgWP4t0+AbejOdO1HgT4hnS9WC1z7HXDKwz0JpEBil2h4xkkTUJsp80qfY1Y7jEN6Em+t06s0feBcnQGsd7Tz3al1kIS/exhNHMlVkAgpon1HhLXMXDc0jmvkbubR1LCu59AGRegfv8tVvfp5OQ9uwHBifQYMJwjsXopheisgI7phde5heluJlvnvYXua9lMzCQWCUx5BQeZWLR9jYGzXdBjMy0PGw0c/bEBTNynWO3yzqDXDGNshmwpROBytaSAyXiOBmkYlk5gwNzE/lQVhKshUIoVGffsE8wKpVg7fG84yKRvgjrvwkL8l9xT/Xipn1jb9Yv+lwUc6PsVtO3bdm5xBH+OjJWiWCawoYKreH62G/ijPwzZvwJ0df6sfaxcl6/4glWsHUql2XAVq6SZGfKNXD/FO2PRPp7AeVYuULYhkiyFgo0rcb/aDRxdkM6cRMAxE+yaIO6Rh05lynuFh+DCpAsJwNxL4Y2KUBbamFusRpief2JjJrEmTDb9vCersWZLACluYh5SvStcYjeGScMKItGWnGtX2KhRorjf497ozqPaKWhIsVz+R4Qwpfn2n/KuhqdgxDJGauz0w0OPpBW4FDJohG5232PEpBUlFsP8MZMuPnd2hVSMeDWnpHIW6MXaQbJ4kWCf7Nq4NV/MGLFmSzNdfvfMPcKuB/wh1sCJYQzpbwwhdtQz3SssNP5BxgBe4plSrC2+X96PcS6D2RnEav9jcOORLXSf1O4nYCPbrtALXAUJKuST+FSAZSxcmnE/GoLZxvvFb7ESDgZOVUxcApj2IdVZl8IYihOxzUkGTsUauJt1g5b5HsKVKjLsCg8JXiPmM6ORKLFSZz5ZVQ+yxioytT+RfPJS9h+aGpS0S2EBN/eyqoErsVyCm3EdlFVt0LcbLBN8b1ff8oniCnqxqmi8nSKl/BhLrDc7P355Jo2QPNbVEN/4IkmznhzbrlDTLCoxtxvU5hY12JbCLWpICgMcxbt8Go76zrskEAbql8KCupHiNw1ibamVTD6NjpNYQnyS/+kGQYnEEhAkloDwB8tldm+CVgLHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=200x100 at 0x7F9888D68358>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 彩色水印\n",
    "green_v = gray_green_map[grayscale]\n",
    "color = (255, green_v, 0)\n",
    "wm_img = np.array(Image.new(mode=\"RGB\", size=wm_img.size, color=color))\n",
    "wm_img[bg_mask] = 255\n",
    "wm_img = Image.fromarray(wm_img)\n",
    "wm_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T12:26:24.691915Z",
     "start_time": "2020-02-22T12:26:24.685045Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_text_mask(img: np.array):\n",
    "    if img.max() <= 1:\n",
    "        return img < 1 / 1.25\n",
    "    else:\n",
    "        return img < 255 / 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T15:24:35.618336Z",
     "start_time": "2020-02-22T15:24:35.569336Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# logits of input images.\n",
    "logits0 = []\n",
    "pred_img = input_img\n",
    "batch_iter = len(input_img) // batch_size\n",
    "batch_iter = batch_iter if len(input_img) % batch_size == 0 else batch_iter + 1\n",
    "for batch_i in range(batch_iter):\n",
    "    batch_img = pred_img[batch_size * batch_i:batch_size * (batch_i + 1)]\n",
    "    batch_len_x = len_x[batch_size * batch_i:batch_size * (batch_i + 1)]\n",
    "    batch_logits0 = sess.run(logits,\n",
    "                             feed_dict={\n",
    "                                 inputs: batch_img,\n",
    "                                 input_seq_len: batch_len_x,\n",
    "                                 dropout_rate: 0,\n",
    "                             })\n",
    "    logits0 += [l for l in batch_logits0]\n",
    "logits0 = np.asarray(logits0)\n",
    "lgt = np.roll(logits0, shift=1, axis=2)  # 可以与charset的index对应上了\n",
    "labels = np.argmax(lgt, axis=-1)  # 概率最大的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# logits of input images.\n",
    "with graph.as_default():\n",
    "    logits0 = sess.run(logits,\n",
    "                        feed_dict={\n",
    "                            inputs: input_img,\n",
    "                            input_seq_len: len_x,\n",
    "                            dropout_rate: 0,\n",
    "                        })\n",
    "lgt = np.roll(logits0, shift=1, axis=2)  # 可以与charset的index对应上了\n",
    "labels = np.argmax(lgt, axis=-1)  # 概率最大的\n",
    "# find the position of target character\n",
    "pos_x_list = []\n",
    "for idx in range(len(labels)):\n",
    "    text_index = decode(labels[idx])\n",
    "    j = 0\n",
    "    for i, c in enumerate(text_index):\n",
    "        if c != '' and ((not (i > 0 and text_index[i] == text_index[i - 1])) or\n",
    "                        (i > 1 and text_index[i] == text_index[i - 2])):\n",
    "            if gt_txt[idx][j] != target_txt[idx][j]:\n",
    "                pos_x_list.append(int(i / len(text_index) * input_img.shape[1]))\n",
    "            j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T13:15:52.570986Z",
     "start_time": "2020-02-22T13:15:52.454728Z"
    }
   },
   "outputs": [],
   "source": [
    "wm0_img_list = []\n",
    "wm_mask_list = []\n",
    "text_mask_list = []\n",
    "y_pos = -int(wm_img.size[0] * np.tan(10 * np.pi / 180))\n",
    "for i in range(len(input_img)):\n",
    "    text_img = show(input_img[i])\n",
    "    text_mask = get_text_mask(np.array(text_img)) # 得到 text 的 mask(bool)\n",
    "    rgb_img = Image.new(mode=\"RGB\", size=text_img.size, color=(255, 255, 255))\n",
    "    rgb_img.paste(wm_img, box=(pos_x_list[i] + 10, y_pos)) # 先贴 wm\n",
    "#     rgb_img.paste(wm_img, box=(pos[i][0][0]+20, y_pos)) # 先贴 wm\n",
    "    wm_mask = (np.array(rgb_img.convert('L')) != 255) # 得到 wm 的 mask(bool)\n",
    "    rgb_img.paste(text_img, mask=cvt2Image(text_mask)) # 再贴 text\n",
    "    \n",
    "    wm0_img_list.append(rgb_img)\n",
    "    wm_mask_list.append(transpose(wm_mask))\n",
    "    text_mask_list.append(transpose(text_mask))\n",
    "wm_mask = np.asarray(wm_mask_list)\n",
    "text_mask = np.asarray(text_mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T13:15:56.434014Z",
     "start_time": "2020-02-22T13:15:56.392921Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wm0_img = np.asarray([cvt2raw(np.array(img.convert('L'))) / 255 for img in wm0_img_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T13:15:57.025750Z",
     "start_time": "2020-02-22T13:15:56.975304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "# 大数据集查看 batch predict\n",
    "record_text = []\n",
    "pred_img = wm0_img\n",
    "batch_iter = len(input_img) // batch_size\n",
    "batch_iter = batch_iter if len(input_img) % batch_size == 0 else batch_iter + 1\n",
    "for batch_i in range(batch_iter):\n",
    "    batch_img = pred_img[batch_size * batch_i:batch_size * (batch_i + 1)]\n",
    "    batch_len_x = len_x[batch_size * batch_i:batch_size * (batch_i + 1)]\n",
    "    batch_text = sess.run(decoded,\n",
    "                              feed_dict={\n",
    "                                  inputs: batch_img,\n",
    "                                  input_seq_len: batch_len_x,\n",
    "                                  dropout_rate: 0,\n",
    "                              })\n",
    "    batch_index = TensorflowModel._TensorflowModel__sparse_to_lists(batch_text)\n",
    "    record_text += [''.join(decode(index)) for index in batch_index]\n",
    "    \n",
    "# # 小数据集查看\n",
    "# with graph.as_default():\n",
    "#     wm0_text = sess.run(decoded,\n",
    "#                         feed_dict={\n",
    "#                             inputs: wm0_img,\n",
    "#                             input_seq_len: len_x,\n",
    "#                             dropout_rate: 0,\n",
    "#                         })\n",
    "#     wm0_index = TensorflowModel._TensorflowModel__sparse_to_lists(wm0_text)\n",
    "#     wm0_text = [''.join(decode(index)) for index in wm0_index]\n",
    "\n",
    "cnt = 0\n",
    "for pred_txt, raw_txt in zip(record_text, gt_txt):\n",
    "    if pred_txt == raw_txt:\n",
    "        cnt += 1\n",
    "print(f\"predict accuracy: {cnt / len(gt_txt)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T13:17:43.017978Z",
     "start_time": "2020-02-22T13:16:08.516699Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/home/chenlu/anaconda2/envs/ocr1/lib/python3.6/site-packages/ipykernel_launcher.py:55: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "100%|██████████| 1000/1000 [01:34<00:00, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost 94.44919872283936 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "target_index_list = [np.asarray([c for c in encode(t)]) for t in target_txt]\n",
    "wm_img = wm0_img\n",
    "nb_iter = 500\n",
    "with graph.as_default():\n",
    "    adv_img = wm_img.copy()\n",
    "    m0 = np.zeros(input_img.shape)\n",
    "    record_iter = np.zeros(input_img.shape[0])  # 0代表没成功\n",
    "    start = time.time()\n",
    "    for i in tqdm(range(nb_iter)):\n",
    "        batch_iter = len(input_img) // batch_size\n",
    "        batch_iter = batch_iter if len(input_img) % batch_size == 0 else batch_iter + 1\n",
    "        for batch_i in range(batch_iter):\n",
    "            batch_input_img = wm_img[batch_size * batch_i:batch_size * (batch_i + 1)]\n",
    "            batch_adv_img = adv_img[batch_size * batch_i:batch_size * (batch_i + 1)]\n",
    "            batch_len_x = len_x[batch_size * batch_i:batch_size * (batch_i + 1)]\n",
    "            batch_m0 = m0[batch_size * batch_i:batch_size * (batch_i + 1)]\n",
    "            batch_target_txt = target_txt[batch_size * batch_i:batch_size * (batch_i + 1)]\n",
    "            batch_tmp_y = [np.asarray([c - 1 for c in encode(t)])for t in batch_target_txt]\n",
    "            batch_y = sparse_tuple_from(batch_tmp_y)\n",
    "            batch_mask = wm_mask[batch_size * batch_i:batch_size * (batch_i + 1)]\n",
    "            batch_record_iter = record_iter[batch_size * batch_i:batch_size * (batch_i + 1)]\n",
    "            \n",
    "            scaled_perturbation = scaled_perturbation_2 if pert_type == '2' else scaled_perturbation_inf\n",
    "            batch_pert = sess.run(scaled_perturbation,\n",
    "                                  feed_dict={\n",
    "                                      inputs: batch_adv_img,\n",
    "                                      input_seq_len: batch_len_x,\n",
    "                                      m: batch_m0,\n",
    "                                      targets: batch_y,\n",
    "                                      mask: batch_mask,\n",
    "                                      dropout_rate: 0,\n",
    "                                  })\n",
    "            batch_pert[batch_record_iter != 0] = 0\n",
    "            batch_adv_img = batch_adv_img + eps_iter * batch_pert\n",
    "            batch_adv_img = batch_input_img + np.clip(batch_adv_img - batch_input_img, -eps, eps)\n",
    "            batch_adv_img = np.clip(batch_adv_img, clip_min, clip_max)\n",
    "            adv_img[batch_size * batch_i:batch_size * (batch_i + 1)] = batch_adv_img\n",
    "        \n",
    "        record_adv_text = []\n",
    "        for batch_i in range(batch_iter):\n",
    "            batch_adv_img = adv_img[batch_size * batch_i:batch_size * (batch_i + 1)]\n",
    "            batch_len_x = len_x[batch_size * batch_i:batch_size * (batch_i + 1)]\n",
    "            batch_target_index = target_index_list[batch_size * batch_i:batch_size * (batch_i + 1)]\n",
    "            batch_adv_text = sess.run(decoded,\n",
    "                                      feed_dict={\n",
    "                                          inputs: batch_adv_img,\n",
    "                                          input_seq_len: batch_len_x,\n",
    "                                          dropout_rate: 0,\n",
    "                                      })\n",
    "            batch_adv_index = TensorflowModel._TensorflowModel__sparse_to_lists(batch_adv_text)\n",
    "            record_adv_text += [''.join(decode(index)) for index in batch_adv_index]\n",
    "            for j in (range(len(batch_target_index))):\n",
    "                # attack img j successfully at iter i\n",
    "                adv_index, target_index = batch_adv_index[j], batch_target_index[j]\n",
    "                idx_j = batch_size * batch_i + j\n",
    "                if np.sum(adv_index != target_index) == 0 and record_iter[idx_j] == 0:\n",
    "                    record_iter[idx_j] = i\n",
    "        if np.sum(record_iter == 0) == 0:  # all examples are successful\n",
    "            print(i, 'break')\n",
    "            break\n",
    "    duration = time.time() - start\n",
    "    print(f\"Time cost {duration} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T13:32:42.673591Z",
     "start_time": "2020-02-22T13:32:42.665137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict accuracy: 0.4\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for pred_t, target_t in zip(record_adv_text, target_txt):\n",
    "    if pred_t == target_t:\n",
    "        cnt += 1\n",
    "print(f\"predict accuracy: {cnt / len(gt_txt)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T13:32:45.076803Z",
     "start_time": "2020-02-22T13:32:45.062709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stater stater\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=193x48 at 0x7F9820374710>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 6\n",
    "print(target_txt[i], record_adv_text[i])\n",
    "show(adv_img[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T12:32:17.057657Z",
     "start_time": "2020-02-22T12:32:17.010084Z"
    }
   },
   "outputs": [],
   "source": [
    "# 大数据集查看 batch predict\n",
    "record_text = []\n",
    "pred_img = adv_img\n",
    "batch_iter = len(input_img) // batch_size\n",
    "batch_iter = batch_iter if len(input_img) % batch_size == 0 else batch_iter + 1\n",
    "for batch_i in range(batch_iter):\n",
    "    batch_img = pred_img[batch_size * batch_i:batch_size * (batch_i + 1)]\n",
    "    batch_len_x = len_x[batch_size * batch_i:batch_size * (batch_i + 1)]\n",
    "    batch_text = sess.run(decoded,\n",
    "                              feed_dict={\n",
    "                                  inputs: batch_img,\n",
    "                                  input_seq_len: batch_len_x,\n",
    "                                  dropout_rate: 0,\n",
    "                              })\n",
    "    batch_index = TensorflowModel._TensorflowModel__sparse_to_lists(batch_text)\n",
    "    record_text += [''.join(decode(index)) for index in batch_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-22T12:33:05.911327Z",
     "start_time": "2020-02-22T12:33:05.901549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for pred_t, target_t in zip(record_text, target_txt):\n",
    "    if pred_t == target_t:\n",
    "        cnt += 1\n",
    "cnt / len(gt_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gray to color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T08:34:40.590148Z",
     "start_time": "2020-02-16T08:34:40.583084Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def cvt2rgb(gray_img: np.array, text_mask: np.array) -> np.array:\n",
    "#     op_mask = (~(gray_img == 255)) & (~text_mask) # not_bg & not_text\n",
    "#     rgb_img = np.array(Image.fromarray(gray_img).convert('RGB'))\n",
    "#     rgb_img[op_mask, 0] = 255\n",
    "#     rgb_img[op_mask, 1] = gray_green_map_array[gray_img[op_mask]]\n",
    "#     rgb_img[op_mask, 2] = 0\n",
    "#     return rgb_img\n",
    "# # 老办法循环\n",
    "# rgb_img_list = []\n",
    "# for i in range(len(text_mask_list)):\n",
    "#     gray_img = np.array(show(adv_img[i]).convert('L'))\n",
    "#     rgb_img = cvt2rgb(gray_img, text_mask_list[i])\n",
    "#     rgb_img_list.append(rgb_img)\n",
    "# i = 40\n",
    "# gray_img = np.array(show(adv_img[i]).convert('L'))\n",
    "# rgb_img = cvt2rgb(gray_img, text_mask_list[i])\n",
    "# Image.fromarray(rgb_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T08:42:04.201704Z",
     "start_time": "2020-02-16T08:42:04.186851Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cvt2rgb(gray_img, text_mask):\n",
    "    gray_img = invert(gray_img)\n",
    "    op_mask = (~(gray_img == 1)) & (~text_mask) # not_bg & not_text\n",
    "    rgb_img = np.ones(list(gray_img.shape)+[3])\n",
    "    rgb_img[:, :, :, 0] = gray_img\n",
    "    rgb_img[:, :, :, 1] = gray_img\n",
    "    rgb_img[:, :, :, 2] = gray_img\n",
    "    rgb_img[op_mask, 0] = 1\n",
    "    rgb_img[op_mask, 1] = (gray_img[op_mask] - 0.299) / 0.587\n",
    "    rgb_img[op_mask, 2] = 0\n",
    "    return invert(rgb_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T08:42:04.691681Z",
     "start_time": "2020-02-16T08:42:04.573556Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rgb_img = cvt2rgb(adv_img, text_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T08:42:06.318091Z",
     "start_time": "2020-02-16T08:42:06.309175Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rgb(rgb_img):\n",
    "    if rgb_img.max() < 1.5:\n",
    "        return Image.fromarray((rgb_img * 255).astype('uint8'))\n",
    "    else:\n",
    "        return Image.fromarray((rgb_img).astype('uint8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "/* ITU-R Recommendation 601-2 (assuming nonlinear RGB) */\n",
    "#define L(rgb)\\\n",
    "    ((INT32) (rgb)[0]*299 + (INT32) (rgb)[1]*587 + (INT32) (rgb)[2]*114) / 1000\n",
    "#define L24(rgb)\\\n",
    "    ((rgb)[0]*19595 + (rgb)[1]*38470 + (rgb)[2]*7471 + 0x8000) >> 16;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr1",
   "language": "python",
   "name": "ocr1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
